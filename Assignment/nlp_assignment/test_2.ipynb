{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan:\n",
    "\n",
    "- Load the data\n",
    "- Visualise\n",
    "- Preprocess\n",
    "- Dataset definition\n",
    "- Model definition\n",
    "- Model training\n",
    "- Model testing\n",
    "- Results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierre/anaconda3/envs/nlpenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler , LabelEncoder\n",
    "\n",
    "from torch.utils.data import DataLoader , Dataset\n",
    "from transformers import BertTokenizer , BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   positive    AMBIENCE#GENERAL    seating   18:25  \\\n",
      "0  positive    AMBIENCE#GENERAL  trattoria   25:34   \n",
      "1  positive        FOOD#QUALITY       food  98:102   \n",
      "2  negative     SERVICE#GENERAL      STAFF    5:10   \n",
      "3  positive  FOOD#STYLE_OPTIONS       menu     4:8   \n",
      "4  positive        FOOD#QUALITY       tuna     4:8   \n",
      "\n",
      "  short and sweet â€“ seating is great:it's romantic,cozy and private.  \n",
      "0  This quaint and romantic trattoria is at the t...                  \n",
      "1  The have over 100 different beers to offer thi...                  \n",
      "2                        THIS STAFF SHOULD BE FIRED.                  \n",
      "3  The menu looked great, and the waiter was very...                  \n",
      "4        The tuna and wasabe potatoes are excellent.                  \n"
     ]
    }
   ],
   "source": [
    "train_path = \"data/traindata.csv\"\n",
    "val_path = \"data/devdata.csv\"\n",
    "\n",
    "df_train = pd.read_csv(train_path, sep='\\t', header=0, index_col=False)\n",
    "df_val = pd.read_csv(val_path, sep='\\t', header=0, index_col=False)\n",
    "\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1502, 4) (1502,)\n",
      "(375, 4) (375,)\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train.iloc[:, 1:]\n",
    "y_train = df_train.iloc[:, 0]\n",
    "print(X_train.shape , y_train.shape)\n",
    "\n",
    "X_val = df_val.iloc[:, 1:]\n",
    "y_val = df_val.iloc[:, 0]\n",
    "print(X_val.shape , y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n",
      "positive    0.701731\n",
      "negative    0.259654\n",
      "neutral     0.038615\n",
      "Name: proportion, dtype: float64\n",
      "positive\n",
      "positive    0.701333\n",
      "negative    0.261333\n",
      "neutral     0.037333\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# check the distribution of the target variable\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_val.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded labels shape: (1502,)\n",
      "Input sentences shape: (1502,)\n",
      "Encoded labels shape: (375,)\n",
      "Input sentences shape: (375,)\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "aspect_encoder = LabelEncoder()\n",
    "polarity_encoder = LabelEncoder()\n",
    "df_train['aspect_category_encoded'] = aspect_encoder.fit_transform(df_train.iloc[:, 1])\n",
    "y_train_encoded = polarity_encoder.fit_transform(y_train)\n",
    "X_train_sentences = df_train.iloc[:, -1] # sentence is the last column\n",
    "print(f\"Encoded labels shape: {y_train_encoded.shape}\")\n",
    "print(f\"Input sentences shape: {X_train_sentences.shape}\")\n",
    "\n",
    "# Validation\n",
    "aspect_encoder_val = LabelEncoder()\n",
    "polarity_encoder_val = LabelEncoder()\n",
    "df_val['aspect_category_encoded'] = aspect_encoder_val.fit_transform(df_val.iloc[:, 1])\n",
    "y_val_encoded = polarity_encoder_val.fit_transform(y_val)\n",
    "X_val_sentences = df_val.iloc[:, -1]\n",
    "print(f\"Encoded labels shape: {y_val_encoded.shape}\")\n",
    "print(f\"Input sentences shape: {X_val_sentences.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, sentences, labels, tokenizer, max_len=128):\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sentence = str(self.sentences.iloc[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "          sentence,\n",
    "          add_special_tokens=True,\n",
    "          max_length=self.max_len,\n",
    "          return_token_type_ids=False,\n",
    "          padding='max_length',\n",
    "          return_attention_mask=True,\n",
    "          return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "          'review_text': sentence,\n",
    "          'input_ids': encoding['input_ids'].flatten(),\n",
    "          'attention_mask': encoding['attention_mask'].flatten(),\n",
    "          'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "dataset = ReviewDataset(X_train_sentences, y_train_encoded, tokenizer)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = ReviewDataset(X_val_sentences, y_val_encoded, tokenizer)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.drop1 = nn.Dropout(p=0.3)  # First dropout layer\n",
    "        # Adding a fully connected layer to introduce more capacity to the model\n",
    "        self.fc1 = nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size // 2)\n",
    "        self.drop2 = nn.Dropout(p=0.2)  # Second dropout layer\n",
    "        # Layer normalization\n",
    "        self.layer_norm = nn.LayerNorm(self.bert.config.hidden_size // 2)\n",
    "        # Final output layer\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size // 2, n_classes)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, pooled_output = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n",
    "        dropped_output = self.drop1(pooled_output)\n",
    "        # Applying the fully connected layer after the first dropout\n",
    "        fc1_output = F.relu(self.fc1(dropped_output))\n",
    "        dropped_output = self.drop2(fc1_output)\n",
    "        # Applying layer normalization\n",
    "        norm_output = self.layer_norm(dropped_output)\n",
    "        return self.out(norm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SentimentClassifier(n_classes=len(polarity_encoder.classes_)).to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "class_proportions = {0: 0.26, 1: 0.04, 2: 0.7}\n",
    "class_weights = {class_label: (1.0 / proportion) for class_label, proportion in class_proportions.items()}\n",
    "weight_sum = sum(class_weights.values())\n",
    "num_classes = len(class_weights)\n",
    "class_weights = {class_label: (weight / weight_sum) * num_classes for class_label, weight in class_weights.items()}\n",
    "weights_tensor = torch.tensor(list(class_weights.values()), dtype=torch.float32)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=weights_tensor).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, n_examples):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for d in data_loader:\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        labels = d[\"labels\"].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            labels = d[\"labels\"].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            \n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # metrics\n",
    "    precision = precision_score(true_labels, predictions, average='weighted', zero_division=0)\n",
    "    recall = recall_score(true_labels, predictions, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted', zero_division=0)\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses), precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data_loader, val_data_loader, loss_fn, optimizer, device, epochs=4):\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch {epoch + 1}/{epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        train_acc, train_loss = train_epoch(model, train_data_loader, loss_fn, optimizer, device, len(train_data_loader.dataset))\n",
    "        print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "        val_acc, val_loss, val_precision, val_recall, val_f1 = eval_model(model, val_data_loader, loss_fn, device, len(val_data_loader.dataset))\n",
    "        print(f'Val loss {val_loss} accuracy {val_acc}')\n",
    "        print(f'Precision: {val_precision}, Recall: {val_recall}, F1-score: {val_f1}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, loader, val_loader, loss_fn, optimizer, 'cuda', epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_with_predictions(model, data_loader, device):\n",
    "    \n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            labels = d[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return predictions, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, true_labels = eval_model_with_predictions(model, val_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=\"Blues\", square=True,\n",
    "            xticklabels=['Predicted Negative', 'Predicted Neutral', 'Predicted Positive'],\n",
    "            yticklabels=['Actual Negative', 'Actual Neutral', 'Actual Positive'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
